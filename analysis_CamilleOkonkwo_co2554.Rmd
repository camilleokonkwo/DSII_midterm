---
title: "Data Science II Midterm Project Analysis"
author: "Camille Okonkwo"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
editor_options: 
  chunk_output_type: console
--- 
\newpage

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(tidymodels)
library(splines)
library(caret)
library(glmnet)
library(table1)
library(kableExtra)
library(summarytools)
library(corrplot)
library(cowplot)
```
\newpage

# Background

To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic. The ultimate goal is to develop a prediction model for recovery time and identify important risk factors for long recovery time.

# Data

The dataset in `recovery.RData` includes data from 3000 participants.  

Here is a description of each variable:

* ID (`id`): Participant ID
* Gender (`gender`): 1 = Male, 0 = Female
* Race/ethnicity (`race`): 1 = White, 2 = Asian, 3 = Black, 4 = Hispanic
* Smoking (`smoking`): Smoking status; 0 = Never smoked, 1 = Former smoker, 2 = Current smoker
* Height (`height`): Height (in centimeters)
* Weight (`weight`): Weight (in kilograms)
* BMI (`bmi`): Body Mass Index; BMI = weight (in kilograms) / height (in meters) squared
* Hypertension (`hypertension`): 0 = No, 1 = Yes
* Diabetes (`diabetes`): 0 = No, 1 = Yes
* Systolic blood pressure (`SBP`): Systolic blood pressure (in mm/Hg)
* LDL cholesterol (`LDL`): LDL (low-density lipoprotein) cholesterol (in mg/dL)
* Vaccination status at the time of infection (`vaccine`): 0 = Not vaccinated, 1 = Vaccinated
* Severity of COVID-19 infection (`severity`): 0 = Not severe, 1= Severe
* Study (`study`): The study (A/B) that the participant belongs to
* Time to recovery (`recovery_time`): Time from COVID-19 infection to recovery in days

## Data Preparation

Partition the dataset into two parts: a matrix of predictors and a vector of response. 

```{r data_partition, echo = T, message = FALSE, results = 'hide', warning=FALSE}
load("data/recovery.RData")

dat = dat |> 
  select(-id)

# matrix of predictors & vector of response for data set exploration
x.dat = model.matrix(recovery_time ~., dat)[, -1]
y.dat = dat$recovery_time
```
\newpage

# Exploratory analysis and data visualization
```{r echo = FALSE, message = FALSE, warning = FALSE}
dat_ds <- dat |> 
  mutate(across(.fns = as.factor)) |>
  rename_with(~str_to_title(.x), everything()) |> 
  mutate(
    Age = as.numeric(Age),
    Gender = factor(Gender,
                    levels = c(0, 1),
                    labels = c("Female", "Male")),
    `Race/Ethnicity` = factor(Race,
                              levels = c(1, 2, 3, 4),
                              labels = c("White", "Asian", "Black", "Hispanic")),
    `Smoking status` = factor(Smoking,
                              levels = c(0, 1, 2),
                              labels = c("Never smoked", "Former smoker",
                                         "Current smoker")),
    Height = as.numeric(Height),
    Weight = as.numeric(Weight),
    `Body Mass Index` = as.numeric(Bmi),
    Hypertension = factor(Hypertension,
                          levels = c(0, 1),
                          labels = c("No", "Yes")),
    Diabetes = factor(Diabetes,
                      levels = c(0, 1),
                      labels = c("No", "Yes")),
    `Systolic Blood Pressure` = as.numeric(Sbp),
    `Low-density lipoprotein cholesterol` = as.numeric(Ldl),
    `Vaccination status at the time of infection` = factor(Vaccine,
                                                           levels = c(0, 1),
                                                           labels = c("Not vaccinated",
                                                                      "Vaccinated")),
    `Severity of COVID-19 infection` = factor(Severity,
                                              levels = c(0, 1),
                                              labels = c("Not severe", "Severe")),
    `Time from COVID-19 infection to recovery` = as.numeric(Recovery_time),
    Study = factor(Study,
                   levels = c("A", "B"),
                   labels = c("Study A", "Study B"))
    )
```

## Descriptive Statistics Table
```{r}
st_options(plain.ascii = FALSE,
           style = "rmarkdown",
           dfSummary.silent = TRUE,
           footnote = NA,
           subtitle.emphasis = FALSE)

dfSummary(dat)

units(dat_ds$Height) <- "cm"
units(dat_ds$Weight) <- "kg"
units(dat_ds$`Body Mass Index`) <- "kg/m^2"
units(dat_ds$`Systolic Blood Pressure`) <- "mm/Hg"
units(dat_ds$`Low-density lipoprotein cholesterol`) <- "mg/dL"
units(dat_ds$`Time from COVID-19 infection to recovery`) <- "days"

descriptive_table <- table1(~ Age + Gender + `Race/Ethnicity` + `Smoking status` + Height + Weight + `Body Mass Index` + Hypertension + Diabetes + `Systolic Blood Pressure` + `Low-density lipoprotein cholesterol` + `Vaccination status at the time of infection` + `Severity of COVID-19 infection` + `Time from COVID-19 infection to recovery` | Study,
                            data = dat_ds,
                            overall = "Total",
                            caption = "Descriptive Statistics")

ds = t1kable(descriptive_table)
ds
```

There are no missing values in the dataset. The distribution of the demographic variables `age`, `gender`, `race` are about the same between treatment groups. Mean `height`, `weight`, `BMI`, `SBP` and `LDL` variables are also similarly distributed between groups. There are more people who are vaccinated than not vaccinated in study group A and B, and also there are more participants who are reported to have not severe COVID-19 infections. `recovery_time` mean and SD is higher for Study B. There is also a larger interval range.

## Response Variable Exploration
```{r}
# Calculate mean and standard deviation
mean_value = mean(dat$recovery_time)
sd_value = sd(dat$recovery_time)

# Define upper and lower bounds
outlier_coeff = 2
outlier_high = mean_value + outlier_coeff * sd_value
outlier_low = mean_value - outlier_coeff * sd_value

recovery_outlier = 
  dat |> 
  filter(recovery_time >= outlier_low & recovery_time <= outlier_high)

# recovery_time boxplot
boxplot_recovery =
  dat |> 
  ggplot(aes(x = recovery_time, y = study)) +
  geom_violin(fill = "skyblue", alpha = 0.3, color= NA) +
  geom_boxplot(fill = NA, color = "blue",
               width = 0.3, coef = outlier_coeff/2) +
  geom_vline(xintercept = c(outlier_low, outlier_high),
             color = "red",linetype = "dashed", size = .5) +
  labs(title = "Distribution of Days to Recovery post COVID-19 Infection by Study Group",
       x = "Recovery Time (days)", y = "Study Group") +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(0, 400, by = 20),  
    labels = seq(0, 400, by = 20)   
  )

# recovery_time histogram
histogram_recovery =
  dat |> 
  ggplot(aes(x = recovery_time)) +
  geom_histogram(bins = 150, fill = "skyblue", color = "blue") +
  geom_vline(xintercept = c(outlier_low, outlier_high),
             color = "red", linetype = "dashed", size = .5) +
  labs(title = "Distribution of Days to Recovery post COVID-19 Infection",
       x = "Recovery Time (days)", y = "Frequency") +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(0, 400, by = 20),  
    labels = seq(0, 400, by = 20)   
  )

combined_recovery =
  plot_grid(histogram_recovery, boxplot_recovery, ncol = 1)

# Show the combined plot
print(combined_recovery)
```

Using a cut-off based on the standard deviation Â± 2 times the mean, there are a total 92 outliers (approximately 3% of the observations). These outliers will be excluded from future analysis. Specifically, among the outliers, 84 belong to the study group B population.

```{r}
# removing recovery_time outliers
dat2 = 
  dat |> 
  filter(recovery_time >= outlier_low & recovery_time <= outlier_high)

x.dat2 = model.matrix(recovery_time ~., dat2)[, -1]
y.dat2 = dat2$recovery_time
```

## Feature Plot
```{r fig.height=4}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(
  x.dat2[, -c(2, 3, 4, 5, 6, 7, 11, 12, 15, 16, 17) ],
  y.dat2,
  plot = "scatter",
  labels = c("", "Y"),
  type = c("p", "smooth"),
  layout = c(3, 3))
```

From the feature plot of the continuous variables, there appears to be no strong linear correlations with our response variable `recovery_time`. `bmi` and `weight` however show a potential non-linear relationship. A GAM or MARS model may be best (**Do we want to do a transformation?**)

## Correlation Matrix
```{r}
corrplot(cor(x.dat2), method = "circle", type = "full")
```

The correlation matrix between predictors indicates multicollinearity between `bmi` and `weight`, `sbp` and `hypertension`, and potentially `bmi` and `height`.

\newpage

# Model Training in `caret`

## Test and Train Data Preparation
```{r}
set.seed(2)

# create a random split of 80% training and 20% test data
data_split <- initial_split(data = dat2, prop = 0.8)

# partitioned datasets
training_data = training(data_split)
testing_data = testing(data_split)

# training data
x <- model.matrix(recovery_time ~ ., training_data)[, -1] # matrix of predictors
head(x)
y <- training_data$recovery_time # vector of response

# testing data
x2 <- model.matrix(recovery_time ~ .,testing_data)[, -1] # matrix of predictors
y2 <- testing_data$recovery_time # vector of response

# setting a 10-fold cross-validation
ctrl <- trainControl(method = "cv", 
                     number = 10,
                     selectionFunction = "best")
```

## Linear Model
```{r}
set.seed(2)

# fit a linear model
lm.fit <- train(x, y, 
                method = "lm",
                trControl = ctrl)

summary(lm.fit)
```

## KNN
```{r}
# knn using `caret`
set.seed(2)

knn.fit <- train(x, y,
                 method = "knn",
                 trControl = ctrl,
                 tuneGrid = expand.grid(k = seq(from = 1, to = 18, by = 1)))

ggplot(knn.fit, highlight = TRUE) + theme_bw()
```

## Ridge Regression
```{r}
# ridge using `caret`
set.seed(2)

ridge.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0,
                                          lambda = exp(seq(1, -3, length=200))),
                   trControl = ctrl)

plot(ridge.fit, xTrans = log)

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)


ridge.pred <- predict(ridge.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((ridge.pred - testing_data[, "recovery_time"])^2)
```

## Lasso
```{r}
set.seed(2)

# lasso using caret
lasso.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-2, -6, length=200))),
                   trControl = ctrl)

plot(lasso.fit, xTrans = log)

lasso.fit$bestTune

# coefficients in the final model
coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)
```

## Elastic Net
```{r fig.height=4}
set.seed(2)

# elastic net using caret
enet.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = seq(0, 1, length =
                                                        25),
                                          lambda = exp(seq(0, -6, length=200))),
                   trControl = ctrl)

enet.fit$bestTune

myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol)) 
plot(enet.fit, par.settings = myPar)

# coefficients in the final model
coef(enet.fit$finalModel, enet.fit$bestTune$lambda)
```

## PCR
```{r}
set.seed(2)

# pcr using caret
pcr.fit <- train(x, y,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp = 1:18),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

predy2.pcr2 <- predict(pcr.fit, newdata = x2) 

mean((y2 - predy2.pcr2)^2)

ggplot(pcr.fit, highlight = TRUE) + theme_bw()
```

## PLS
```{r}
set.seed(2)

# pls using caret
pls.fit <- train(x, y,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:18),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

predy2.pls2 <- predict(pls.fit, newdata = x2) 

mean((y2 - predy2.pls2)^2)

ggplot(pls.fit, highlight = TRUE) + theme_bw()
```

## GAM
```{r}
set.seed(2)

gam.fit <- train(x, y,
                  method = "gam",
                  tuneGrid = data.frame(method = "GCV.Cp",
                                        select = c(TRUE, FALSE)),
                  trControl = ctrl)

gam.fit$bestTune

gam.fit$finalModel

coef(gam.fit$finalModel)
plot(gam.fit$finalModel)
```

## MARS
```{r}
# set grid
mars_grid <- expand.grid(degree = 1:4, nprune = 1:20)

set.seed(2)

# fit a MARS model
mars.fit <- train(x, y,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl)
# plot
ggplot(mars.fit, highlight = TRUE)

# best tuning parameters
mars.fit$bestTune

# regression function
mars.fit$finalModel

# report the regression function
summary(mars.fit)
coef(mars.fit$finalModel)

# test error
pred.mars <- predict(mars.fit, newdata = testing_data)

test.error.mars <- mean((pred.mars - y2)^2)
```

# Model Comparison
```{r}
# compare models
resamp <- resamples(list(knn = knn.fit, ridge = ridge.fit, lasso = lasso.fit, enet = enet.fit, pcr = pcr.fit, pls = pls.fit, gam = gam.fit, mars = mars.fit, lm = lm.fit))

summary(resamp)

parallelplot(resamp, metric = "RMSE")

bwplot(resamp, metric = "RMSE")
```

GAM has lowest mean and median RMSE -> model I pick. GAM is a good choice since it incorporates non-linear terms by adding the smoothing function, as well as linear terms. GAM also performs model selection for us. 

# Test Data Simulation
```{r}

```

