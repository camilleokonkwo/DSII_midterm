---
title: "Data Science II Midterm Project Analysis"
author: "Camille Okonkwo"
output:
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lipsum}
- \pagestyle{fancy}
- \fancyhead[R]{\thepage}
- \fancypagestyle{plain}{\pagestyle{fancy}}
editor_options: 
  chunk_output_type: console
--- 
\newpage

```{r setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(tidymodels)
library(splines)
library(caret)
library(glmnet)
library(table1)
library(kableExtra)
library(summarytools)
library(corrplot)
library(cowplot)
```
\newpage

# Background

To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic. The ultimate goal is to develop a prediction model for recovery time and identify important risk factors for long recovery time.

# Data

The dataset in `recovery.RData` includes data from 3000 participants.  

Here is a description of each variable:

* ID (`id`): Participant ID
* Gender (`gender`): 1 = Male, 0 = Female
* Race/ethnicity (`race`): 1 = White, 2 = Asian, 3 = Black, 4 = Hispanic
* Smoking (`smoking`): Smoking status; 0 = Never smoked, 1 = Former smoker, 2 = Current smoker
* Height (`height`): Height (in centimeters)
* Weight (`weight`): Weight (in kilograms)
* BMI (`bmi`): Body Mass Index; BMI = weight (in kilograms) / height (in meters) squared
* Hypertension (`hypertension`): 0 = No, 1 = Yes
* Diabetes (`diabetes`): 0 = No, 1 = Yes
* Systolic blood pressure (`SBP`): Systolic blood pressure (in mm/Hg)
* LDL cholesterol (`LDL`): LDL (low-density lipoprotein) cholesterol (in mg/dL)
* Vaccination status at the time of infection (`vaccine`): 0 = Not vaccinated, 1 = Vaccinated
* Severity of COVID-19 infection (`severity`): 0 = Not severe, 1= Severe
* Study (`study`): The study (A/B) that the participant belongs to
* Time to recovery (`recovery_time`): Time from COVID-19 infection to recovery in days

## Data Preparation

Partition the dataset into two parts: a matrix of predictors and a vector of response. 

```{r data_partition, echo = T, message = FALSE, results = 'hide', warning=FALSE}
load("data/recovery.RData")

dat = dat |> 
  select(-id)

# matrix of predictors & vector of response for data set exploration
x.dat = model.matrix(recovery_time ~., dat)[, -1]
y.dat = dat$recovery_time
```
\newpage

# Exploratory analysis and data visualization
```{r echo = FALSE, message = FALSE, warning = FALSE}
dat_ds <- dat |> 
  mutate(across(.fns = as.factor)) |>
  rename_with(~str_to_title(.x), everything()) |> 
  mutate(
    Age = as.numeric(Age),
    Gender = factor(Gender,
                    levels = c(0, 1),
                    labels = c("Female", "Male")),
    `Race/Ethnicity` = factor(Race,
                              levels = c(1, 2, 3, 4),
                              labels = c("White", "Asian", "Black", "Hispanic")),
    `Smoking status` = factor(Smoking,
                              levels = c(0, 1, 2),
                              labels = c("Never smoked", "Former smoker",
                                         "Current smoker")),
    Height = as.numeric(Height),
    Weight = as.numeric(Weight),
    `Body Mass Index` = as.numeric(Bmi),
    Hypertension = factor(Hypertension,
                          levels = c(0, 1),
                          labels = c("No", "Yes")),
    Diabetes = factor(Diabetes,
                      levels = c(0, 1),
                      labels = c("No", "Yes")),
    `Systolic Blood Pressure` = as.numeric(Sbp),
    `Low-density lipoprotein cholesterol` = as.numeric(Ldl),
    `Vaccination status at the time of infection` = factor(Vaccine,
                                                           levels = c(0, 1),
                                                           labels = c("Not vaccinated",
                                                                      "Vaccinated")),
    `Severity of COVID-19 infection` = factor(Severity,
                                              levels = c(0, 1),
                                              labels = c("Not severe", "Severe")),
    `Time from COVID-19 infection to recovery` = as.numeric(Recovery_time),
    Study = factor(Study,
                   levels = c("A", "B"),
                   labels = c("Study A", "Study B"))
    )
```

## Descriptive Statistics Table
```{r}
st_options(plain.ascii = FALSE,
           style = "rmarkdown",
           dfSummary.silent = TRUE,
           footnote = NA,
           subtitle.emphasis = FALSE)

dfSummary(dat)

units(dat_ds$Height) <- "cm"
units(dat_ds$Weight) <- "kg"
units(dat_ds$`Body Mass Index`) <- "kg/m^2"
units(dat_ds$`Systolic Blood Pressure`) <- "mm/Hg"
units(dat_ds$`Low-density lipoprotein cholesterol`) <- "mg/dL"
units(dat_ds$`Time from COVID-19 infection to recovery`) <- "days"

descriptive_table <- table1(~ Age + Gender + `Race/Ethnicity` + `Smoking status` + Height + Weight + `Body Mass Index` + Hypertension + Diabetes + `Systolic Blood Pressure` + `Low-density lipoprotein cholesterol` + `Vaccination status at the time of infection` + `Severity of COVID-19 infection` + `Time from COVID-19 infection to recovery` | Study,
                            data = dat_ds,
                            overall = "Total",
                            caption = "Descriptive Characteristics of Participants, Stratified by Source Study")

ds = t1kable(descriptive_table)
ds
```

There are no missing values in the dataset. The distribution of the demographic variables `age`, `gender`, `race` are about the same between treatment groups. Mean `height`, `weight`, `BMI`, `SBP` and `LDL` variables are also similarly distributed between groups. There are more people who are vaccinated than not vaccinated in study group A and B, and also there are more participants who are reported to have not severe COVID-19 infections. `recovery_time` mean and SD is higher for Study B. There is also a larger interval range.

## Response Variable Exploration
```{r}
# Calculate mean and standard deviation
mean_value = mean(dat$recovery_time)
sd_value = sd(dat$recovery_time)

# Define upper and lower bounds
outlier_coeff = 1.5
outlier_high = mean_value + outlier_coeff * sd_value
outlier_low = mean_value - outlier_coeff * sd_value

# recovery_time boxplot
boxplot_recovery =
  dat |> 
  ggplot(aes(x = recovery_time, y = study)) +
  geom_violin(fill = "skyblue", alpha = 0.3, color= NA) +
  geom_boxplot(fill = NA, color = "blue",
               width = 0.3, coef = outlier_coeff/2) +
  geom_vline(xintercept = c(outlier_low, outlier_high),
             color = "red",linetype = "dashed", size = .5) +
  labs(title = "Distribution of Days to Recovery post COVID-19 Infection by Study Group",
       x = "Recovery Time (days)", y = "Study Group") +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(0, 400, by = 20),  
    labels = seq(0, 400, by = 20)   
  )

# recovery_time histogram
histogram_recovery =
  dat |> 
  ggplot(aes(x = recovery_time)) +
  geom_histogram(bins = 150, fill = "skyblue", color = "blue") +
  geom_vline(xintercept = c(outlier_low, outlier_high),
             color = "red", linetype = "dashed", size = .5) +
  labs(title = "Distribution of Days to Recovery post COVID-19 Infection",
       x = "Recovery Time (days)", y = "Frequency") +
  theme_minimal() +
  scale_x_continuous(
    breaks = seq(0, 400, by = 20),  
    labels = seq(0, 400, by = 20)   
  )

combined_recovery =
  plot_grid(histogram_recovery, boxplot_recovery, ncol = 1)

# Show the combined plot
print(combined_recovery)
```

Using a cut-off based on the standard deviation Â± 1.5 times the mean, these outliers will be excluded from future analysis. This cutoff was used to keep the distributions of study groups A & B similar.

```{r}
# removing recovery_time outliers
dat2 = 
  dat |> 
  filter(recovery_time > outlier_low & recovery_time < outlier_high)

x.dat2 = model.matrix(recovery_time ~., dat2)[, -1]
y.dat2 = dat2$recovery_time
```

# Univariate Analysis of Predictors
```{r}
predictor_variables <- c("age", "gender", "race", "smoking", "height", "weight", "bmi", "hypertension", "diabetes", "SBP", "LDL", "vaccine", "severity", "study")

univar_linear <- lapply(predictor_variables, function(var) {
  formula <- as.formula(paste("recovery_time ~ ", var))
  model <- lm(formula, data = dat2)
    tidy(model) |> 
      filter(term != "(Intercept)") |> 
      mutate(p.value.sig = ifelse(p.value < 0.05, "*", ""))
})

univar_summary <- bind_rows(univar_linear)

knitr::kable(univar_summary) 
```
`race`, `diabetes`, and `LDL` appear to be insignificant predictors of `recovery_time` according to the univariate linear analysis.

## Feature Plot
```{r fig.height=4}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

featurePlot(
  x.dat2[, -c(2, 3, 4, 5, 6, 7, 11, 12, 15, 16, 17) ],
  y.dat2,
  plot = "scatter",
  labels = c("", "Y"),
  type = c("p", "smooth"),
  layout = c(3, 3))
```

From the feature plot of the continuous variables, there appears to be no strong linear correlations with our response variable `recovery_time`. `bmi` and `weight` however show a potential non-linear relationship. A GAM or MARS model may be best.

## Correlation Matrix
```{r}
corrplot(cor(x.dat2), method = "circle", type = "full")
```

The correlation matrix between predictors indicates multicollinearity between `bmi` and `weight`, `sbp` and `hypertension`, and potentially `bmi` and `height`.

\newpage

# Model Training in `caret`

## Test and Train Data Preparation
```{r}
set.seed(1234)

# create a random split of 80% training and 20% test data
data_split <- initial_split(data = dat2, prop = 0.8)

# partitioned datasets
training_data = training(data_split)
testing_data = testing(data_split)

# training data
x <- model.matrix(recovery_time ~ ., training_data)[, -1] # matrix of predictors
head(x)
y <- training_data$recovery_time # vector of response

# testing data
x2 <- model.matrix(recovery_time ~ .,testing_data)[, -1] # matrix of predictors
y2 <- testing_data$recovery_time # vector of response

# setting a 10-fold cross-validation
ctrl <- trainControl(method = "cv", 
                     number = 10,
                     selectionFunction = "best")
```

## Linear Model
```{r}
set.seed(1234)

# fit a linear model
lm.fit <- train(x, y, 
                method = "lm",
                trControl = ctrl)

summary(lm.fit)
```

## KNN
```{r}
# knn using `caret`
set.seed(1234)

knn.fit <- train(x, y,
                 method = "knn",
                 trControl = ctrl,
                 tuneGrid = expand.grid(k = seq(from = 1, to = 18, by = 1)))

ggplot(knn.fit, highlight = TRUE) + theme_bw()
```

## Ridge
```{r}
# ridge using `caret`
set.seed(1234)

ridge.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0,
                                          lambda = exp(seq(1, -3, length=200))),
                   trControl = ctrl)

plot(ridge.fit, xTrans = log)

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)


ridge.pred <- predict(ridge.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((ridge.pred - testing_data[, "recovery_time"])^2)
```

## Lasso
```{r}
set.seed(1234)

# lasso using caret
lasso.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(-2, -6, length=200))),
                   trControl = ctrl)

plot(lasso.fit, xTrans = log)

lasso.fit$bestTune

# coefficients in the final model
coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)

lasso.pred <- predict(lasso.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((lasso.pred - testing_data[, "recovery_time"])^2)
```

## Elastic Net
```{r fig.height=4}
set.seed(1234)

# elastic net using caret
enet.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = seq(0, 1, length =
                                                        25),
                                          lambda = exp(seq(0, -6, length=200))),
                   trControl = ctrl)

enet.fit$bestTune

myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol)) 
plot(enet.fit, par.settings = myPar)

# coefficients in the final model
coef(enet.fit$finalModel, enet.fit$bestTune$lambda)

enet.pred <- predict(enet.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((enet.pred - testing_data[, "recovery_time"])^2)
```

## PCR
```{r}
set.seed(1234)

# pcr using caret
pcr.fit <- train(x, y,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp = 1:17),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(pcr.fit, highlight = TRUE) + theme_bw()

pcr.pred <- predict(pcr.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((pcr.pred - testing_data[, "recovery_time"])^2)
```

## PLS
```{r}
set.seed(1234)

# pls using caret
pls.fit <- train(x, y,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:17),
                 trControl = ctrl,
                 preProcess = c("center", "scale"))

ggplot(pls.fit, highlight = TRUE) + theme_bw()

pls.pred <- predict(pls.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((pls.pred - testing_data[, "recovery_time"])^2)
```

## GAM
```{r}
set.seed(1234)

gam.fit <- train(x, y,
                  method = "gam",
                  tuneGrid = data.frame(method = "GCV.Cp",
                                        select = c(TRUE, FALSE)),
                  trControl = ctrl)

gam.fit$bestTune

gam.fit$finalModel

coef(gam.fit$finalModel)
plot(gam.fit$finalModel)

gam.pred <- predict(gam.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((gam.pred - testing_data[, "recovery_time"])^2)
```

## MARS
```{r}
# set grid
mars_grid <- expand.grid(degree = 1:4, nprune = 1:20)

set.seed(1234)

# fit a MARS model
mars.fit <- train(x, y,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl)
# plot
ggplot(mars.fit, highlight = TRUE)

# best tuning parameters
mars.fit$bestTune

# regression function
mars.fit$finalModel

plot(mars.fit$finalModel)

# report the regression function
summary(mars.fit)
coef(mars.fit$finalModel)

mars.pred <- predict(pls.fit, newdata = model.matrix(recovery_time ~ ., testing_data)[,-1])

# test error
mean((mars.pred - testing_data[, "recovery_time"])^2)
```

# Model Comparison
```{r}
# compare models
resamp <- resamples(list(knn = knn.fit, ridge = ridge.fit, lasso = lasso.fit, enet = enet.fit, pcr = pcr.fit, pls = pls.fit, gam = gam.fit, mars = mars.fit, lm = lm.fit))

summary(resamp)

parallelplot(resamp, metric = "RMSE")

bwplot(resamp, metric = "RMSE")
```

MARS has lowest mean and median RMSE -> model I pick. GAM is also a good choice since it incorporates non-linear terms by adding the smoothing function, as well as linear terms. GAM also performs model selection for us. We will compare the performance of GAM and MARS on the testing data to determine which model is best. 

# Testing Data Analysis
```{r}
# MARS Prediction
mars.pred = predict(mars.fit, newdata = model.matrix(recovery_time ~ .,testing_data)[,-1])

# MARS test error
mean((mars.pred - testing_data[, "recovery_time"])^2)

# GAM Prediction
gam.pred = predict(gam.fit, newdata = model.matrix(recovery_time ~ .,testing_data)[,-1])

# GAM test error
mean((gam.pred - testing_data[, "recovery_time"])^2)
```

Based on the testing data, we should actually go with the GAM model over the MARS since the test error is lower. 

